{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01515e8-c2c5-4f7e-bcae-6d8559f41239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de9e6eb-0958-42eb-807b-04e51fd71df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForQuestionAnswering were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "file_path = \"./train_converted.jsonl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'allenai/longformer-base-4096'\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    'allenai/longformer-base-4096', return_dict=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7c8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend 'Venite Ad Me Omnes'. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9eb6616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "print(test[514:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1362618-8cce-4759-8214-6f77876c33d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7939\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenized = []\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "file_path = \"./train_converted_enriched.jsonl\"\n",
    "from datasets import Dataset\n",
    "\n",
    "original_data = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        data_line = json.loads(line)\n",
    "        data_line[\"question\"] += 'NIL </ec>'\n",
    "        original_data.append(data_line)\n",
    "print(len(original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65e910b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experience Unlimited album) : album by Experience Unlimited </ec> NIL </ec>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[1]['question'][97:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f04504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18448\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenized = []\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "file_path = \"./aida_train_converted.jsonl\"\n",
    "from datasets import Dataset\n",
    "\n",
    "original_data_aida = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        data_line = json.loads(line)\n",
    "        for training_item in data_line:\n",
    "            original_data_aida.append(training_item)\n",
    "print(len(original_data_aida))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08dafa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'is carts based upon a variety of criteria. IMG also includes a genome annotation pipeline that integrates information from several tools, including  [START_ENT] kegg [END_ENT], Pfam, InterPro, and the Gene Ontology, among others. Users can also type or upload their own gene annotations (called MyIMG gene annotations) ',\n",
       " 'question': 'Kegg Pipe Organ Builders </ec> KEGG </ec>  NIL </ec>',\n",
       " 'answers': {'answer_start': [31], 'text': ['KEGG']}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6f78a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7939\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "concat = [] + original_data\n",
    "random.shuffle(concat)\n",
    "print(len(concat))\n",
    "train_original = concat[: int(len(concat) * 0.7)]\n",
    "eval_original = concat[int(len(concat) * 0.7) :]\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"context\": [item[\"question\"] for item in train_original],\n",
    "        \"question\": [item[\"context\"] for item in train_original],\n",
    "        \"answers\": [item[\"answers\"] for item in train_original],\n",
    "    }\n",
    ")\n",
    "dataset_ev = Dataset.from_dict(\n",
    "    {\n",
    "        \"context\": [item[\"question\"] for item in eval_original],\n",
    "        \"question\": [item[\"context\"] for item in eval_original],\n",
    "        \"answers\": [item[\"answers\"] for item in eval_original],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fa5c63-f01a-4b97-9cc0-4f6c3d6821f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers'],\n",
       "    num_rows: 7917\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7350b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Silent film </ec> Photoplay </ec> Photoplay edition </ec> Photoplay (album) </ec> Film </ec>  NIL </ec>',\n",
       " 'question': ' film Here We Go Round the Mulberry Bush (1968) where he was cast as Jamie McGregor, a teenager who finds it difficult to lose his virginity.  [START_ENT] photoplay [END_ENT] magazine called Evans a bright and exciting new actor , and The Sunday Telegraph described his screen debut as brilliant .Here We ',\n",
       " 'answers': {'answer_start': [18], 'text': ['Photoplay']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f94614f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_alignement(context, answer):\n",
    "    \"\"\"Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here.\"\"\"\n",
    "    gold_text = answer[\"text\"][0]\n",
    "    start_idx = context.find(gold_text)\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "    return start_idx, end_idx\n",
    "    # if context[start_idx:end_idx] == gold_text:\n",
    "    #     return start_idx, end_idx       # When the gold label position is good\n",
    "    # elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "    #     return start_idx-1, end_idx-1   # When the gold label is off by one character\n",
    "    # elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "    #     return start_idx-2, end_idx-2   # When the gold label is off by two character\n",
    "    # else:\n",
    "    #     raise ValueError()\n",
    "\n",
    "\n",
    "# Tokenize our training dataset\n",
    "def convert_to_features(example):\n",
    "    try:\n",
    "        # Tokenize contexts and questions (as pairs of inputs)\n",
    "        input_pairs = [example[\"question\"], example[\"context\"]]\n",
    "        encodings = tokenizer.encode_plus(\n",
    "            input_pairs, pad_to_max_length=True, max_length=512\n",
    "        )\n",
    "        context_encodings = tokenizer.encode_plus(example[\"context\"])\n",
    "\n",
    "        # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methodes.\n",
    "        # this will give us the position of answer span in the context text\n",
    "\n",
    "        if example[\"answers\"][\"answer_start\"][0] == -1:\n",
    "            print(\"l'e' che\")\n",
    "            start_idx = example[\"context\"].find(\"NIL\")\n",
    "            example[\"answers\"][\"answer_start\"][0] = start_idx\n",
    "            example[\"answers\"][\"text\"][0] = \"NIL\"\n",
    "\n",
    "        start_idx, end_idx = get_correct_alignement(\n",
    "            example[\"context\"], example[\"answers\"]\n",
    "        )\n",
    "        start_positions_context = context_encodings.char_to_token(start_idx)\n",
    "        end_positions_context = context_encodings.char_to_token(end_idx - 1)\n",
    "\n",
    "        # here we will compute the start and end position of the answer in the whole example\n",
    "        # as the example is encoded like this <s> question</s></s> context</s>\n",
    "        # and we know the postion of the answer in the context\n",
    "        # we can just find out the index of the sep token and then add that to position + 1 (+1 because there are two sep tokens)\n",
    "        # this will give us the position of the answer span in whole example\n",
    "        sep_idx = encodings[\"input_ids\"].index(tokenizer.sep_token_id)\n",
    "        start_positions = start_positions_context + sep_idx + 1\n",
    "        end_positions = end_positions_context + sep_idx + 1\n",
    "\n",
    "        encodings.update(\n",
    "            {\n",
    "                \"start_positions\": start_positions,\n",
    "                \"end_positions\": end_positions,\n",
    "                \"attention_mask\": encodings[\"attention_mask\"],\n",
    "            }\n",
    "        )\n",
    "        return encodings\n",
    "    except Exception as e:\n",
    "        print(\"errors\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352ecd7d-1d89-4113-bb3c-0fd8837334a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7425800779044a32bef5ea352ecc7bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5557 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/rub/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69146058fa94e54b06a7b697cc0a0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = dataset.map(convert_to_features)\n",
    "eval_ds = dataset_ev.map(convert_to_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daed8460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Dookie United Football Club Dookie Dookie, Victoria Dookie (dog) NIL',\n",
       " 'question': 'ash; 8 September 1991) was an Australian politician.He was born in Corowa to labourer David Drysdale Morton and Annie Margaret Ellis. He grew up in  [START_ENT] dookie [END_ENT] and served with the 6th Light Horse in World War I. On his return he was a local government officer. On 24 June 1922 he married Winifred Keir',\n",
       " 'answers': {'answer_start': [35], 'text': ['Dookie, Victoria']}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36abcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    \"./TrainedModelSpecialTokenNILEL\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca745971-3963-42de-af93-1282e75daab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator\n",
    "# args = TrainingArguments(\n",
    "#     f\"longformer-finetuned-squad\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-squad\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ac65fb-0f2a-401f-9cb6-0c3d98ce3c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rub/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33magazzi-ruben99\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rub/Documents/Borsa/Tesi/TESTFS/wandb/run-20231116_145316-kn8e1k3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agazzi-ruben99/huggingface/runs/kn8e1k3b' target=\"_blank\">peach-sun-55</a></strong> to <a href='https://wandb.ai/agazzi-ruben99/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agazzi-ruben99/huggingface' target=\"_blank\">https://wandb.ai/agazzi-ruben99/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agazzi-ruben99/huggingface/runs/kn8e1k3b' target=\"_blank\">https://wandb.ai/agazzi-ruben99/huggingface/runs/kn8e1k3b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4042f9159d94fde872069b1d60adf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LongformerTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3687, 'learning_rate': 2.2863309352517985e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449d44b1d1264507bfba569a189b8803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2803889513015747, 'eval_runtime': 59.0977, 'eval_samples_per_second': 40.306, 'eval_steps_per_second': 5.042, 'epoch': 1.0}\n",
      "{'loss': 0.226, 'learning_rate': 1.566906474820144e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6ada3480934ad3a7148ab3e05ac265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29688161611557007, 'eval_runtime': 58.6467, 'eval_samples_per_second': 40.616, 'eval_steps_per_second': 5.081, 'epoch': 2.0}\n",
      "{'loss': 0.1284, 'learning_rate': 8.47482014388489e-06, 'epoch': 2.16}\n",
      "{'loss': 0.0643, 'learning_rate': 1.2805755395683455e-06, 'epoch': 2.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc19ba1a696c46b3b946eb225318705c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30743542313575745, 'eval_runtime': 58.0988, 'eval_samples_per_second': 40.999, 'eval_steps_per_second': 5.129, 'epoch': 3.0}\n",
      "{'train_runtime': 1940.6356, 'train_samples_per_second': 8.59, 'train_steps_per_second': 1.074, 'train_loss': 0.19021372600710934, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2085, training_loss=0.19021372600710934, metrics={'train_runtime': 1940.6356, 'train_samples_per_second': 8.59, 'train_steps_per_second': 1.074, 'train_loss': 0.19021372600710934, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77766c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./TrainedModelSpecialTokenNILEL_enriched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e58634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shutdown scheduled for Mon 2023-11-13 17:33:04 CET, use 'shutdown -c' to cancel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['shutdown', '-h'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Shutdown\n",
    "subprocess.run([\"shutdown\", \"-h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71805d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6b3f211-be57-4c73-9a66-1d65c7dade62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Give It All (Train song) </ec> Give It All (film) </ec> Give It All </ec>  NIL </ec>',\n",
       " 'question': \"t==Helen McNichol (Tania Raymonde), a high school senior, is in love with Stanford Prescott (Ryan Merriman), her jock boyfriend, and has decided to  [START_ENT] give it all [END_ENT] up to him. At least until she learns that her name is written in the high school football team's secret Bang Book and it is Stanford's j\",\n",
       " 'answers': {'answer_start': [75], 'text': ['NIL']}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e969f",
   "metadata": {},
   "source": [
    "## Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e32b05cb-b7b8-4d79-81cd-a7b93faa23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': 'Air War (game) </ec> Air War </ec> Indo-Pakistani Air War of 1965 </ec> World War II </ec> Aerial warfare </ec>  NIL </ec>', 'question': 'Units, 16) (2004). Osprey Publishing (UK) (). 128 pgs. * Winter, Denis. First of the Few. London: Allen Lane/Penguin, 1982. Coverage of the British  [START_ENT] air war [END_ENT], with extensive bibliographical notes. * Wise, S.F., Canadian Airmen and the First World War: The Official History of the Royal Canadian Air', 'answers': {'answer_start': [113], 'text': ['NIL']}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LongformerTokenizer, LongformerForQuestionAnswering\n",
    "\n",
    "index = i\n",
    "question = dataset_ev[index][\"context\"]\n",
    "text = dataset_ev[index][\"question\"]\n",
    "print(dataset_ev[index])\n",
    "input_pairs = [text, question]\n",
    "encodings = tokenizer.encode_plus(input_pairs, return_tensors=\"pt\").to(\"cuda\")\n",
    "encodings_context = tokenizer.encode_plus(question, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5025a308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': 'Air War (game) </ec> Air War </ec> Indo-Pakistani Air War of 1965 </ec> World War II </ec> Aerial warfare </ec>  NIL </ec>', 'question': 'Units, 16) (2004). Osprey Publishing (UK) (). 128 pgs. * Winter, Denis. First of the Few. London: Allen Lane/Penguin, 1982. Coverage of the British  [START_ENT] air war [END_ENT], with extensive bibliographical notes. * Wise, S.F., Canadian Airmen and the First World War: The Official History of the Royal Canadian Air', 'answers': {'answer_start': [113], 'text': ['NIL']}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_ev)):\n",
    "    if dataset_ev[i][\"answers\"][\"text\"][0] == 'NIL':\n",
    "        print(dataset_ev[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "210a30f9-34f0-4fdd-ae8c-8c0ac335a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Air War (game) </ec> Air War </ec> Indo-Pakistani Air War of 1965 </ec> World War II </ec> Aerial warfare </ec>  NIL </ec>',\n",
       " 'question': 'Units, 16) (2004). Osprey Publishing (UK) (). 128 pgs. * Winter, Denis. First of the Few. London: Allen Lane/Penguin, 1982. Coverage of the British  [START_ENT] air war [END_ENT], with extensive bibliographical notes. * Wise, S.F., Canadian Airmen and the First World War: The Official History of the Royal Canadian Air',\n",
       " 'answers': {'answer_start': [113], 'text': ['NIL']}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ev[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06717d4b-ef7d-40c3-85b7-3436b9bee1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encodings[\"input_ids\"]\n",
    "attention_mask = encodings[\"attention_mask\"]\n",
    "start_scores, end_scores = model(\n",
    "    encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"]\n",
    ")\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(encodings_context[\"input_ids\"][0].tolist())\n",
    "start = torch.argmax(\n",
    "    start_scores\n",
    ")  # Get the most likely beginning of answer with the argmax of the score\n",
    "end = (\n",
    "    torch.argmax(end_scores) + 1\n",
    ")  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "\n",
    "answer_tokens = input_ids[0, start.item() : end.item() + 1]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f99facfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_answer(answer):\n",
    "    modified_answer = answer.replace(\"</ec>\", \"\")\n",
    "    modified_answer2 = modified_answer.replace(\"</\", \"\")\n",
    "    modified_answer2 = modified_answer2.split(':')[0]\n",
    "    return modified_answer2.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33b31251-8f73-48c5-89e3-a1a02d4447df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIL\n"
     ]
    }
   ],
   "source": [
    "print(process_answer(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48e08ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot\n",
    "\n",
    "\n",
    "def get_wikidata(wikipedia_title):\n",
    "    try:\n",
    "        site = pywikibot.Site(\"en\", \"wikipedia\")  # Connect to the English Wikipedia\n",
    "        page = pywikibot.Page(site, wikipedia_title)  # Get the Wikipedia page\n",
    "        item = pywikibot.ItemPage.fromPage(page)  # Get the associated Wikidata item\n",
    "        item.get()\n",
    "        if \"en\" in item.descriptions:  # Fetch all data of the Wikidata item\n",
    "            return item.descriptions[\"en\"]  # Return the English description\n",
    "        else:\n",
    "            return \"\"\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1555cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(data_entry):\n",
    "    question = data_entry[\"input\"]\n",
    "    context = \"\"\n",
    "    for item in data_entry[\"candidates\"]:\n",
    "        desc = get_wikidata(item)\n",
    "        context += item + f\" : {desc} </ec> \"\n",
    "    input_pairs = [question, context]\n",
    "\n",
    "    encodings = tokenizer.encode_plus(input_pairs, return_tensors=\"pt\").to(\"cuda\")\n",
    "    start_scores, end_scores = model(\n",
    "        encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"]\n",
    "    )\n",
    "\n",
    "    start = torch.argmax(\n",
    "        start_scores\n",
    "    )  # Get the most likely beginning of answer with the argmax of the score\n",
    "    end = (\n",
    "        torch.argmax(end_scores) + 1\n",
    "    )  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer_tokens = encodings[\"input_ids\"][0, start.item() : end.item() + 1]\n",
    "    answer = process_answer(tokenizer.decode(answer_tokens))\n",
    "    return {\"correct\": data_entry[\"output\"], \"predicted\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7871c50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    \"./TrainedModelSpecialTokenNILEL\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee371f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7939 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_wikidata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m             dataset\u001b[39m.\u001b[39mappend(item)\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m tqdm(dataset):\n\u001b[0;32m---> 16\u001b[0m     pred \u001b[39m=\u001b[39m make_prediction(item)\n\u001b[1;32m     17\u001b[0m     results\u001b[39m.\u001b[39mappend(pred)\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mmake_prediction\u001b[0;34m(data_entry)\u001b[0m\n\u001b[1;32m      3\u001b[0m context \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data_entry[\u001b[39m\"\u001b[39m\u001b[39mcandidates\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m----> 5\u001b[0m     desc \u001b[39m=\u001b[39m get_wikidata(item)\n\u001b[1;32m      6\u001b[0m     context \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m item \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m : \u001b[39m\u001b[39m{\u001b[39;00mdesc\u001b[39m}\u001b[39;00m\u001b[39m </ec> \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m input_pairs \u001b[39m=\u001b[39m [question, context]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_wikidata' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "results = []\n",
    "file_path = \"./train.jsonl\"\n",
    "dataset = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        data_line = json.loads(line)\n",
    "        for item in data_line:\n",
    "            dataset.append(item)\n",
    "\n",
    "for item in tqdm(dataset):\n",
    "    pred = make_prediction(item)\n",
    "    results.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daca2118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': [{'answer': 'Tasmanian Legislative Council',\n",
       "   'provenance': [{'title': 'Tasmanian Legislative Council'}]}],\n",
       " 'predicted': 'Tasmanian Legislative Council'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ba25a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6821/6821 [00:00<00:00, 1016606.77it/s]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for result in tqdm(results):\n",
    "  if result['predicted'] == result['correct'][0]['answer']:\n",
    "    correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2024e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is 0.7312710746224894\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy of the model is {correct/len(results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
