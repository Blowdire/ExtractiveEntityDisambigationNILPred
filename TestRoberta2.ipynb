{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d01515e8-c2c5-4f7e-bcae-6d8559f41239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af2596-b907-49cc-b6c3-2190e8af746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"tesi\", name=\"bigbird\")  # args = TrainingArguments(\n",
    "wandb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de9e6eb-0958-42eb-807b-04e51fd71df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./robertaLargeIofNil/checkpoint-2178\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    \"./robertaLargeIofNil/checkpoint-2178\", return_dict=False\n",
    ").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1362618-8cce-4759-8214-6f77876c33d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7939\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenized = []\n",
    "file_path = \"./nil_el_instanceof.jsonl\"\n",
    "from datasets import Dataset\n",
    "\n",
    "original_data = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        data_line = json.loads(line)\n",
    "        \n",
    "        \n",
    "        original_data.append(data_line)\n",
    "print(len(original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f04504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18448\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenized = []\n",
    "file_path = \"./aida_train_instanceof.jsonl\"\n",
    "from datasets import Dataset\n",
    "\n",
    "original_data_aida = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        data_line = json.loads(line)\n",
    "        \n",
    "        # additional_question = \"<additional> \"\n",
    "        # try:\n",
    "        #     for related in data_line[\"most_related\"]:\n",
    "        #         length = len(related)\n",
    "        #         if len(related) == 4:\n",
    "        #             additional_question += related[2]\n",
    "        #             additional_question += \" \"\n",
    "        # except:\n",
    "        #     None\n",
    "        # additional_question += \"</additional>\"\n",
    "        # data_line[\"context\"] += additional_question\n",
    "        original_data_aida.append(data_line)\n",
    "print(len(original_data_aida))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6f78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(original_data_aida)\n",
    "#concat = original_data_aida\n",
    "concat =original_data_aida[:int(len(original_data_aida)* 0.7)] + original_data\n",
    "\n",
    "\n",
    "random.shuffle(concat)\n",
    "#print(len(concat))\n",
    "train_original = concat[: int(len(concat) * 0.95)]\n",
    "eval_original = concat[int(len(concat) * 0.95) : ]\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"context\": [item[\"question\"] for item in train_original],\n",
    "        \"question\": [item[\"context\"] for item in train_original],\n",
    "        \"answers\": [item[\"answers\"] for item in train_original],\n",
    "    }\n",
    ")\n",
    "dataset_ev = Dataset.from_dict(\n",
    "    {\n",
    "        \"context\": [item[\"question\"] for item in eval_original],\n",
    "        \"question\": [item[\"context\"] for item in eval_original],\n",
    "        \"answers\": [item[\"answers\"] for item in eval_original],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94614f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_alignement(context, answer):\n",
    "    \"\"\"Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here.\"\"\"\n",
    "    gold_text = answer[\"text\"][0]\n",
    "    \n",
    "    start_idx = context.find(gold_text)\n",
    "    end_idx = context.find(\"</ec>\", start_idx)\n",
    "    return start_idx, end_idx\n",
    "    # if context[start_idx:end_idx] == gold_text:\n",
    "    #     return start_idx, end_idx       # When the gold label position is good\n",
    "    # elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "    #     return start_idx-1, end_idx-1   # When the gold label is off by one character\n",
    "    # elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "    #     return start_idx-2, end_idx-2   # When the gold label is off by two character\n",
    "    # else:\n",
    "    #     raise ValueError()\n",
    "\n",
    "\n",
    "# Tokenize our training dataset\n",
    "def convert_to_features(example):\n",
    "    try:\n",
    "        # Tokenize contexts and questions (as pairs of inputs)\n",
    "\n",
    "        input_pairs = [example[\"question\"], example[\"context\"]]\n",
    "        encodings = tokenizer.encode_plus(\n",
    "            input_pairs, pad_to_max_length=True, truncation=\"only_second\"\n",
    "        )\n",
    "        context_encodings = tokenizer.encode_plus(example[\"context\"])\n",
    "\n",
    "        # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methodes.\n",
    "        # this will give us the position of answer span in the context text\n",
    "\n",
    "        start_idx, end_idx = get_correct_alignement(\n",
    "            example[\"context\"], example[\"answers\"]\n",
    "        )\n",
    "        if end_idx != -1 and start_idx != -1:\n",
    "            try:\n",
    "                start_positions_context = context_encodings.char_to_token(start_idx)\n",
    "                end_positions_context = context_encodings.char_to_token(end_idx)\n",
    "\n",
    "                # here we will compute the start and end position of the answer in the whole example\n",
    "                # as the example is encoded like this <s> question</s></s> context</s>\n",
    "                # and we know the postion of the answer in the context\n",
    "                # we can just find out the index of the sep token and then add that to position + 1 (+1 because there are two sep tokens)\n",
    "                # this will give us the position of the answer span in whole example\n",
    "                sep_idx = encodings[\"input_ids\"].index(tokenizer.sep_token_id)\n",
    "                start_positions = start_positions_context + sep_idx\n",
    "                end_positions = end_positions_context + sep_idx + 1\n",
    "                #print(tokenizer.decode\n",
    "                #(encodings[\"input_ids\"][start_positions:end_positions]))\n",
    "                encodings.update(\n",
    "                    {\n",
    "                        \"start_positions\": start_positions,\n",
    "                        \"end_positions\": end_positions,\n",
    "                        \"attention_mask\": encodings[\"attention_mask\"],\n",
    "                    }\n",
    "                )\n",
    "                return encodings\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            print(\"qu\")\n",
    "            encodings.update(\n",
    "                {\n",
    "                    \"start_positions\": start_idx,\n",
    "                    \"end_positions\": end_idx,\n",
    "                    \"attention_mask\": encodings[\"attention_mask\"],\n",
    "                    \"is_nil\": 1 if example[\"answers\"][\"text\"][0] == \"Not In Candidates\" else 0\n",
    "                }\n",
    "            )\n",
    "            return encodings\n",
    "    except Exception as e:\n",
    "        print(\"errors\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ecd7d-1d89-4113-bb3c-0fd8837334a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.map(convert_to_features)\n",
    "eval_ds = dataset_ev.map(convert_to_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8bff14-4fde-4476-b465-6f6cc047553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03702e3-22f2-46b1-9387-a536b79d06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump( train_ds, './dumps/aidaTrainIOF.dump',)\n",
    "joblib.dump( eval_ds, './dumps/aidaEvalIOF.dump',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = joblib.load('./dumps/aidaTrainNERBigBird.dump')\n",
    "eval_ds = joblib.load('./dumps/aidaEvalNERBigBird.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49e60b5c-b03e-4ebf-888a-d0a10390b3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qey95ft) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3qey95ft). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">desert-silence-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/agazzi-ruben99/uncategorized\" target=\"_blank\">https://wandb.ai/agazzi-ruben99/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/agazzi-ruben99/uncategorized/runs/2yhntv94\" target=\"_blank\">https://wandb.ai/agazzi-ruben99/uncategorized/runs/2yhntv94</a><br/>\n",
       "                Run data is saved locally in <code>/home/agazzi/wandb/run-20231218_100154-2yhntv94</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2yhntv94)</h1><iframe src=\"https://wandb.ai/agazzi-ruben99/uncategorized/runs/2yhntv94\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fceae26cfd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca745971-3963-42de-af93-1282e75daab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "\n",
    "import wandb\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.current_device()\n",
    "\n",
    "#wandb.init(project=\"tesi\", name=\"robertaAidaLargeNERNIL\")  # args = TrainingArguments(\n",
    "#     f\"longformer-finetuned-squad\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"robertaLargefNil\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"wandb\",\n",
    "    load_best_model_at_end=False,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=1,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_eval_batch_size=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=100,\n",
    "    num_train_epochs=14,\n",
    "    weight_decay=0.02,\n",
    "    fp16=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ac65fb-0f2a-401f-9cb6-0c3d98ce3c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: answers, context, question.\n",
      "***** Running training *****\n",
      "  Num examples = 19809\n",
      "  Num Epochs = 14\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 100\n",
      "  Gradient Accumulation steps = 100\n",
      "  Total optimization steps = 2772\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33magazzi-ruben99\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">robertaLargefNil</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/agazzi-ruben99/huggingface\" target=\"_blank\">https://wandb.ai/agazzi-ruben99/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/agazzi-ruben99/huggingface/runs/zp9jbbva\" target=\"_blank\">https://wandb.ai/agazzi-ruben99/huggingface/runs/zp9jbbva</a><br/>\n",
       "                Run data is saved locally in <code>/home/agazzi/wandb/run-20231218_194507-zp9jbbva</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1171' max='2772' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1171/2772 4:01:55 < 5:31:19, 0.08 it/s, Epoch 5.91/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.337372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.329125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.356657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.387810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/extend/lib/python3.9/site-packages/transformers/trainer.py:1355: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: answers, context, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to robertaLargefNil/checkpoint-198\n",
      "Configuration saved in robertaLargefNil/checkpoint-198/config.json\n",
      "Model weights saved in robertaLargefNil/checkpoint-198/pytorch_model.bin\n",
      "tokenizer config file saved in robertaLargefNil/checkpoint-198/tokenizer_config.json\n",
      "Special tokens file saved in robertaLargefNil/checkpoint-198/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: answers, context, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to robertaLargefNil/checkpoint-396\n",
      "Configuration saved in robertaLargefNil/checkpoint-396/config.json\n",
      "Model weights saved in robertaLargefNil/checkpoint-396/pytorch_model.bin\n",
      "tokenizer config file saved in robertaLargefNil/checkpoint-396/tokenizer_config.json\n",
      "Special tokens file saved in robertaLargefNil/checkpoint-396/special_tokens_map.json\n",
      "Deleting older checkpoint [robertaLargefNil/checkpoint-198] due to args.save_total_limit\n",
      "/opt/miniconda3/envs/extend/lib/python3.9/site-packages/transformers/trainer.py:1355: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: answers, context, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to robertaLargefNil/checkpoint-594\n",
      "Configuration saved in robertaLargefNil/checkpoint-594/config.json\n",
      "Model weights saved in robertaLargefNil/checkpoint-594/pytorch_model.bin\n",
      "tokenizer config file saved in robertaLargefNil/checkpoint-594/tokenizer_config.json\n",
      "Special tokens file saved in robertaLargefNil/checkpoint-594/special_tokens_map.json\n",
      "Deleting older checkpoint [robertaLargefNil/checkpoint-396] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: answers, context, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to robertaLargefNil/checkpoint-792\n",
      "Configuration saved in robertaLargefNil/checkpoint-792/config.json\n",
      "Model weights saved in robertaLargefNil/checkpoint-792/pytorch_model.bin\n",
      "tokenizer config file saved in robertaLargefNil/checkpoint-792/tokenizer_config.json\n",
      "Special tokens file saved in robertaLargefNil/checkpoint-792/special_tokens_map.json\n",
      "Deleting older checkpoint [robertaLargefNil/checkpoint-594] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: answers, context, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to robertaLargefNil/checkpoint-990\n",
      "Configuration saved in robertaLargefNil/checkpoint-990/config.json\n",
      "Model weights saved in robertaLargefNil/checkpoint-990/pytorch_model.bin\n",
      "tokenizer config file saved in robertaLargefNil/checkpoint-990/tokenizer_config.json\n",
      "Special tokens file saved in robertaLargefNil/checkpoint-990/special_tokens_map.json\n",
      "Deleting older checkpoint [robertaLargefNil/checkpoint-792] due to args.save_total_limit\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77766c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./RoBertAAida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71805d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3f211-be57-4c73-9a66-1d65c7dade62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e969f",
   "metadata": {},
   "source": [
    "## Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99facfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alzenau'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_brackets(input_string):\n",
    "    stack = []\n",
    "    brackets = {\"(\": \")\", \"{\": \"}\", \"[\": \"]\"}\n",
    "    for char in input_string:\n",
    "        if char in brackets.keys():\n",
    "            stack.append(char)\n",
    "        elif char in brackets.values():\n",
    "            if not stack or brackets[stack.pop()] != char:\n",
    "                return False\n",
    "    return not stack\n",
    "\n",
    "\n",
    "def process_answer(answer, candidates):\n",
    "    if answer == \"Not In Candidates\":\n",
    "        return answer\n",
    "    else:\n",
    "        modified_answer = answer.split(\"</ec>\")[0]\n",
    "        modified_answer = modified_answer.split(\": instance of \")[0]\n",
    "        modified_answer = modified_answer.split(\": instance\")[0]\n",
    "        modified_answer = modified_answer.replace(\"<s>\", \"\")\n",
    "        modified_answer = modified_answer.replace(\"</ec\", \"\")\n",
    "        modified_answer = modified_answer.replace(\"</s>\", \"\")\n",
    "        modified_answer = modified_answer.replace(\"<s\", \"\")\n",
    "        modified_answer = modified_answer.replace(\"</\", \"\")\n",
    "        modified_answer = modified_answer.replace(\" ec\", \"\")\n",
    "        modified_answer = modified_answer.replace(\">\", \"\")\n",
    "        modified_answer = modified_answer.strip()\n",
    "        if not check_brackets(modified_answer):\n",
    "            modified_answer = modified_answer.replace(\"(\", \"\")\n",
    "            modified_answer = modified_answer.replace(\")\", \"\")\n",
    "        if modified_answer == \"Not In Candidates\":\n",
    "            modified_answer = \"NIL\"\n",
    "        if modified_answer == \"\":\n",
    "            modified_answer = \"Not In Candidates\"\n",
    "        if modified_answer not in candidates:\n",
    "            modified_answer = \"Not In Candidates\"\n",
    "        return modified_answer\n",
    "\n",
    "\n",
    "process_answer(\"> Alzenau </\", [\"Alzenau\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1555cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_prediction(data_entry, nil_prediction):\n",
    "    with torch.no_grad():\n",
    "        question = data_entry[\"input\"]\n",
    "        context = \"\"\n",
    "        # if nil_prediction:\n",
    "        #     context += \" Not In Candidates </ec> \"\n",
    "        index = 0\n",
    "        added = False\n",
    "        for item in data_entry[\"candidates\"]:\n",
    "            context += item + f\" </ec> \"\n",
    "            index += 1\n",
    "            if index == 1 and nil_prediction:\n",
    "                context += \" Not In Candidates : instance of Unknown </ec> \"\n",
    "                added = True\n",
    "        if not added and nil_prediction:\n",
    "            context = \" Not In Candidates : instance of Unknown </ec> \" + context\n",
    "        input_pairs = [question, context]\n",
    "\n",
    "        encodings = tokenizer.encode_plus(\n",
    "            input_pairs, return_tensors=\"pt\", truncation=\"only_second\"\n",
    "        ).to(\"cuda\")\n",
    "        start_scores, end_scores = model(\n",
    "            encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"]\n",
    "        )\n",
    "        start_scores = F.softmax(start_scores, dim=1)\n",
    "        end_scores = F.softmax(end_scores, dim=1)\n",
    "        # start_scores.to(\"cpu\")\n",
    "        # end_scores.to(\"cpu\")\n",
    "        start = torch.argmax(\n",
    "            start_scores\n",
    "        )  # Get the most likely beginning of answer with the argmax of the score\n",
    "        end = (\n",
    "            torch.argmax(end_scores) + 1\n",
    "        )  # Get the most likely end of answer with the argmax of the score\n",
    "        mean_score = 0\n",
    "        try:\n",
    "            mean_score = end_scores[0][end.item()] + start_scores[0][start.item()]\n",
    "        except:\n",
    "            None\n",
    "        answer_tokens = encodings[\"input_ids\"][0, start.item() : end.item() + 1]\n",
    "        answer = \"\"\n",
    "\n",
    "        answer = process_answer(tokenizer.decode(answer_tokens), context)\n",
    "        classified = 0\n",
    "        if (mean_score < 0.9) and nil_prediction:\n",
    "            answer = \"Not In Candidates\"\n",
    "        else:\n",
    "            if answer == \"\":\n",
    "                answer = \"Not In Candidates\"\n",
    "        del encodings\n",
    "        del end_scores\n",
    "        del start_scores\n",
    "        del start\n",
    "        del end\n",
    "        score = float(mean_score)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return {\n",
    "            \"correct\": data_entry[\"output\"],\n",
    "            \"non_processed\": tokenizer.decode(answer_tokens),\n",
    "            \"predicted\": answer,\n",
    "            \"input_phrase\": question,\n",
    "            \"scores\": score,\n",
    "            \"candidates\": context,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c023f-a73d-4d5e-a753-418ff74c0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee371f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4485/4485 [11:24<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "results = []\n",
    "file_path = \"./aida-test-kilt-instanceof.jsonl\"\n",
    "dataset = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object\n",
    "        data_line = json.loads(line)\n",
    "\n",
    "        dataset.append(data_line)\n",
    "\n",
    "for item in tqdm(dataset):\n",
    "    try:\n",
    "        pred = make_prediction(item, False)\n",
    "        results.append(pred)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daca2118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3968"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ba25a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4485/4485 [00:00<00:00, 814383.89it/s]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "correct_trace = []\n",
    "wrong = []\n",
    "correct_nil = 0\n",
    "wrong_nil = 0\n",
    "full_data = []\n",
    "for result in tqdm(results):\n",
    "  processed = result['predicted']\n",
    "  if processed == result['correct'][0]['answer']:\n",
    "    correct += 1\n",
    "    correct_trace.append(result)\n",
    "    if processed == 'Not In Candidates':\n",
    "        correct_nil += 1\n",
    "  else:\n",
    "    if result['correct'][0]['answer'] == 'Not In Candidates':\n",
    "        wrong_nil += 1\n",
    "    wrong.append(result)\n",
    "  full_data.append({'score': result['scores'], 'nil': int(result['correct'][0]['answer'] == 'Not In Candidates')} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68f13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is 0.8923076923076924\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy of the model is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy in nil prediction is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcorrect_nil\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcorrect_nil\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mwrong_nil\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy of the model is {correct/len(results)}\")\n",
    "print(f\"accuracy in nil prediction is: {correct_nil/(correct_nil+wrong_nil)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2024e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is 0.836890243902439\n",
      "accuracy in nil prediction is: 0.5935483870967742\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy of the model is {correct/len(results)}\")\n",
    "print(f\"accuracy in nil prediction is: {correct_nil/(correct_nil+wrong_nil)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b285bc-679f-41a8-9859-3f594a4b276c",
   "metadata": {},
   "source": [
    "-  Base: 65.9%\n",
    "-  Large: 73.21%(enriched) - 74.65% (standard)\n",
    "-  Large EN: 76.66%\n",
    "-  large NER: 75.5%\n",
    "-  Base-NER: 66.35%\n",
    "\n",
    "## MSNBC large\n",
    "-  No EN: 91.92%\n",
    "-  No Instance Of: 92.83% - Yes: 93.44%\n",
    "-  EN: 92.8\n",
    "-  Large NER: 92.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365299e-e8f0-4651-b752-ff7d6adcb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1197d1e9-3e52-4ca4-a959-57f6751f6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_df = pd.DataFrame(full_data)\n",
    "df = pd.DataFrame(wrong)\n",
    "df_c = pd.DataFrame(correct_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "878b3a7c-82f8-434d-8767-739109fcf191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iraq War : instance of military offensive </ec> Iraq national football team : instance of national association football team </ec> Anglo-Iraqi War : instance of war </ec> Iraq Football Association : instance of association football federation </ec> Iraqi Army : instance of Unknown </ec> Iraq at the 2004 Summer Olympics : instance of Olympic delegation </ec> Iraq at the 2008 Summer Olympics : instance of Olympic delegation </ec> Iraq at the 1960 Summer Olympics : instance of Olympic delegation </ec> Iraq prison abuse scandals : instance of scandal </ec> Iraq at the Asian Games : instance of nation at sport competition </ec> Iraq national basketball team : instance of Unknown </ec> History of Iraq (2003–11) : instance of Unknown </ec> Iraq at the 2006 Asian Games : instance of nation at sport competition </ec> Iraqi Premier League : instance of Unknown </ec> Iraq national futsal team : instance of national futsal team </ec> Afro-Iraqi : instance of Unknown </ec> Iraq–Turkey relations : instance of bilateral relation </ec> Gulf War : instance of war </ec> Iraqi Canadian : instance of Unknown </ec> Iraqi Kurdistan : instance of geographic location </ec> Security Detachment Iraq (Australia) : instance of military unit </ec> Iraq al-Manshiyya : instance of village </ec> Opposition to the Iraq War : instance of political position </ec> Supreme Iraqi Criminal Tribunal : instance of Wikimedia list article </ec> Iraqi Air Force : instance of air force </ec> Embassy of Iraq in Washington, D.C. : instance of Unknown </ec> Operation Telic : instance of Unknown </ec> Iraq Liberation Act : instance of Act of Congress in the United States </ec> United States support for Iraq during the Iran–Iraq war : instance of Unknown </ec> Saddam Hussein : instance of human </ec> Iraq War troop surge of 2007 : instance of war </ec> Open for Business (album) : instance of Unknown </ec> `Iraq al Amir : instance of Unknown </ec> Iraq Suwaydan : instance of village </ec> Mesopotamian Arabic : instance of modern language </ec> Iraq national baseball team : instance of national sports team </ec> Iraqi revolt against the British : instance of Unknown </ec> RAF Iraq Command : instance of military unit </ec> Iraq Family Health Survey : instance of Unknown </ec> Iraqi records in athletics : instance of Unknown </ec> Iraqi people : instance of Unknown </ec> 2011 Iraqi protests : instance of protest </ec> Iraqi passport : instance of Unknown </ec> Iraq–United States relations : instance of bilateral relation </ec> Iraqi Communist Party : instance of communist party </ec> Iraq at the 1996 Summer Olympics : instance of Olympic delegation </ec> Iraqi security forces : instance of Security Forces </ec> China–Iraq relations : instance of bilateral relation </ec> Iraq at the Olympics : instance of Olympic delegation </ec> Iraqi dinar : instance of dinar </ec> Iraq at the 2009 World Championships in Athletics : instance of nation at the World Athletics Championships </ec> Denmark–Iraq relations : instance of bilateral relation </ec> Iraq and weapons of mass destruction : instance of aspect in a geographic region </ec> Iraq–Russia relations : instance of bilateral relation </ec> Iraq at the Paralympics : instance of Paralympics delegation </ec> Academi : instance of Unknown </ec> Iraq at the 2011 World Aquatics Championships : instance of nation at sport competition </ec> Iraqi Republic Railways : instance of national railway </ec> Iraq at the 1964 Summer Olympics : instance of Olympic delegation </ec> Iraq at the 2008 Summer Paralympics : instance of Paralympics delegation </ec> Iraq at the 2000 Summer Olympics : instance of Olympic delegation </ec> Iraqi Army Ranks Insignia : instance of Unknown </ec> Iraq–Pakistan relations : instance of bilateral relation </ec> Iraq at the 2010 Summer Youth Olympics : instance of nation at sport competition </ec> Iraq at the 1988 Summer Olympics : instance of Olympic delegation </ec> Iraq at the 1992 Summer Olympics : instance of Olympic delegation </ec> Iraq–United Kingdom relations : instance of bilateral relation </ec> Iraqi cuisine : instance of national cuisine </ec> Iraq–Israel relations : instance of bilateral relation </ec> Mawtini : instance of national anthem </ec> Not In Candidates </ec>  Not In Candidates </ec> '"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c3df84-751a-4ade-9364-a9078478e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>non_processed</th>\n",
       "      <th>predicted</th>\n",
       "      <th>input_phrase</th>\n",
       "      <th>scores</th>\n",
       "      <th>candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[{'answer': 'Abdelbaset al-Megrahi', 'provenan...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>is that the judges may not punish Abu Talib un...</td>\n",
       "      <td>0.998908</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[{'answer': 'New York', 'provenance': [{'title...</td>\n",
       "      <td>&gt; New York City : instance of city in the Unit...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>N Y Times News Service LR QC QL GROSSE POINTE ...</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>New York : instance of Wikimedia disambiguatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[{'answer': 'Michigan Department of Natural Re...</td>\n",
       "      <td>&lt;/s&gt;Minnesota Department of Natural Resources ...</td>\n",
       "      <td>Minnesota Department of Natural Resources</td>\n",
       "      <td>injured since the hunting season opened on Nov...</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>Minnesota Department of Natural Resources : in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[{'answer': 'Joel Grossman', 'provenance': [{'...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>Welcome to this hour of VOA News Now I m Erin ...</td>\n",
       "      <td>0.925782</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[{'answer': 'Florida Legislature', 'provenance...</td>\n",
       "      <td>&lt;/s&gt;Legislature : instance of Unknown &lt;/ec</td>\n",
       "      <td>Legislature</td>\n",
       "      <td>we have had a Supreme Court challenge over pre...</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>Legislature : instance of Unknown &lt;/ec&gt; Federa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[{'answer': 'Netzarim (settlement)', 'provenan...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>the Israeli army began bulldozing Palestinian ...</td>\n",
       "      <td>0.978799</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[{'answer': 'State Street Corporation', 'prove...</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>shareholders with 55 percent of the merged com...</td>\n",
       "      <td>1.005916</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[{'answer': 'Time Inc.', 'provenance': [{'titl...</td>\n",
       "      <td>&lt;/s&gt;Time (magazine) : instance of news magazin...</td>\n",
       "      <td>Time (magazine)</td>\n",
       "      <td>company you re going to be a happy camper That...</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>Time (magazine) : instance of news magazine &lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[{'answer': 'Warner Communications', 'provenan...</td>\n",
       "      <td>&gt; Warner Bros. : instance of entertainment com...</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>re going to be a happy camper That view is wid...</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>Warner Music Group : instance of record compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[{'answer': 'Janus Capital Group', 'provenance...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>McNamee of Integral Capital which sold its 404...</td>\n",
       "      <td>0.999672</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[{'answer': 'Green Party of Florida', 'provena...</td>\n",
       "      <td>&lt;/s&gt;Green Party of the United States : instanc...</td>\n",
       "      <td>Green Party of the United States</td>\n",
       "      <td>feel guilty about her vote I voted for Nader b...</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>Green Party of the United States : instance of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[{'answer': 'Ocean Spray (cooperative)', 'prov...</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>of a gigantic ear of corn as big as a Buick Do...</td>\n",
       "      <td>1.006418</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[{'answer': 'InStyle', 'provenance': [{'title'...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>Live Did shoppers at the New York supermarket ...</td>\n",
       "      <td>0.333244</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[{'answer': 'Campbell Soup Company', 'provenan...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>Was it a coincidence that an ad for the Carnat...</td>\n",
       "      <td>0.960894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[{'answer': 'Levi Strauss &amp; Co.', 'provenance'...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>s Cream of Mushroom soup that carried the slog...</td>\n",
       "      <td>0.247320</td>\n",
       "      <td>Levi : instance of human biblical figure &lt;/ec&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[{'answer': 'Sprint Nextel', 'provenance': [{'...</td>\n",
       "      <td></td>\n",
       "      <td>Not In Candidates</td>\n",
       "      <td>disparate advertisers Empire Blue Cross Blue S...</td>\n",
       "      <td>0.331737</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              correct  \\\n",
       "20  [{'answer': 'Abdelbaset al-Megrahi', 'provenan...   \n",
       "21  [{'answer': 'New York', 'provenance': [{'title...   \n",
       "22  [{'answer': 'Michigan Department of Natural Re...   \n",
       "23  [{'answer': 'Joel Grossman', 'provenance': [{'...   \n",
       "24  [{'answer': 'Florida Legislature', 'provenance...   \n",
       "25  [{'answer': 'Netzarim (settlement)', 'provenan...   \n",
       "26  [{'answer': 'State Street Corporation', 'prove...   \n",
       "27  [{'answer': 'Time Inc.', 'provenance': [{'titl...   \n",
       "28  [{'answer': 'Warner Communications', 'provenan...   \n",
       "29  [{'answer': 'Janus Capital Group', 'provenance...   \n",
       "30  [{'answer': 'Green Party of Florida', 'provena...   \n",
       "31  [{'answer': 'Ocean Spray (cooperative)', 'prov...   \n",
       "32  [{'answer': 'InStyle', 'provenance': [{'title'...   \n",
       "33  [{'answer': 'Campbell Soup Company', 'provenan...   \n",
       "34  [{'answer': 'Levi Strauss & Co.', 'provenance'...   \n",
       "35  [{'answer': 'Sprint Nextel', 'provenance': [{'...   \n",
       "\n",
       "                                        non_processed  \\\n",
       "20                                                      \n",
       "21  > New York City : instance of city in the Unit...   \n",
       "22  </s>Minnesota Department of Natural Resources ...   \n",
       "23                                                      \n",
       "24         </s>Legislature : instance of Unknown </ec   \n",
       "25                                                      \n",
       "26                                               </s>   \n",
       "27  </s>Time (magazine) : instance of news magazin...   \n",
       "28  > Warner Bros. : instance of entertainment com...   \n",
       "29                                                      \n",
       "30  </s>Green Party of the United States : instanc...   \n",
       "31                                               </s>   \n",
       "32                                                      \n",
       "33                                                      \n",
       "34                                                      \n",
       "35                                                      \n",
       "\n",
       "                                    predicted  \\\n",
       "20                          Not In Candidates   \n",
       "21                              New York City   \n",
       "22  Minnesota Department of Natural Resources   \n",
       "23                          Not In Candidates   \n",
       "24                                Legislature   \n",
       "25                          Not In Candidates   \n",
       "26                          Not In Candidates   \n",
       "27                            Time (magazine)   \n",
       "28                               Warner Bros.   \n",
       "29                          Not In Candidates   \n",
       "30           Green Party of the United States   \n",
       "31                          Not In Candidates   \n",
       "32                          Not In Candidates   \n",
       "33                          Not In Candidates   \n",
       "34                          Not In Candidates   \n",
       "35                          Not In Candidates   \n",
       "\n",
       "                                         input_phrase    scores  \\\n",
       "20  is that the judges may not punish Abu Talib un...  0.998908   \n",
       "21  N Y Times News Service LR QC QL GROSSE POINTE ...  0.999954   \n",
       "22  injured since the hunting season opened on Nov...  0.999875   \n",
       "23  Welcome to this hour of VOA News Now I m Erin ...  0.925782   \n",
       "24  we have had a Supreme Court challenge over pre...  0.999995   \n",
       "25  the Israeli army began bulldozing Palestinian ...  0.978799   \n",
       "26  shareholders with 55 percent of the merged com...  1.005916   \n",
       "27  company you re going to be a happy camper That...  0.999403   \n",
       "28  re going to be a happy camper That view is wid...  0.999943   \n",
       "29  McNamee of Integral Capital which sold its 404...  0.999672   \n",
       "30  feel guilty about her vote I voted for Nader b...  0.999997   \n",
       "31  of a gigantic ear of corn as big as a Buick Do...  1.006418   \n",
       "32  Live Did shoppers at the New York supermarket ...  0.333244   \n",
       "33  Was it a coincidence that an ad for the Carnat...  0.960894   \n",
       "34  s Cream of Mushroom soup that carried the slog...  0.247320   \n",
       "35  disparate advertisers Empire Blue Cross Blue S...  0.331737   \n",
       "\n",
       "                                           candidates  \n",
       "20                                                     \n",
       "21  New York : instance of Wikimedia disambiguatio...  \n",
       "22  Minnesota Department of Natural Resources : in...  \n",
       "23                                                     \n",
       "24  Legislature : instance of Unknown </ec> Federa...  \n",
       "25                                                     \n",
       "26                                                     \n",
       "27  Time (magazine) : instance of news magazine </...  \n",
       "28  Warner Music Group : instance of record compan...  \n",
       "29                                                     \n",
       "30  Green Party of the United States : instance of...  \n",
       "31                                                     \n",
       "32                                                     \n",
       "33                                                     \n",
       "34  Levi : instance of human biblical figure </ec>...  \n",
       "35                                                     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "offset=1\n",
    "df.iloc[offset *n : offset*n + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be007697-5520-4786-b03a-4fa61bf30b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./errorsNil.csv\")\n",
    "df_c.to_csv(\"./correctNil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de164f-a8a4-4241-b9a6-3b88323bd64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
